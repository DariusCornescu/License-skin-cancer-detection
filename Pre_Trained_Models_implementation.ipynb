{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kZsaxy8h2zAR",
        "outputId": "db03809d-5d1f-4728-97b4-cd028fbf5344"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "Drive mounted\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Drive mounted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lOC2PUkZ3FJH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import time\n",
        "from collections import Counter\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_fscore_support"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hJJic_p9P_Qw"
      },
      "source": [
        "## Training Environment and Computational Considerations\n",
        "\n",
        "Due to the substantial computational requirements associated with training deep neural networks, **Google Colaboratory** was selected as the primary training environment. This decision was motivated by the impracticality of training large-scale, pre-trained architectures locally within reasonable time constraints.\n",
        "\n",
        "### Model Architectures\n",
        "\n",
        "The following architectures were trained and evaluated:\n",
        "\n",
        "* **ResNet152V2**\n",
        "* **EfficientNetV2B0**\n",
        "* **InceptionResNetV2**\n",
        "* **MobileNetV3Large**\n",
        "* **Custom-CNN**\n",
        "\n",
        "### Hardware Acceleration\n",
        "\n",
        "All experiments were conducted using **NVIDIA A100 GPU accelerators**, which significantly reduced training time and enabled the execution of large-scale experiments that would otherwise be infeasible on local hardware.\n",
        "\n",
        "---\n",
        "\n",
        "## Data Loading Bottleneck\n",
        "\n",
        "During the initial training phase, a substantial **I/O bottleneck** was observed when loading image data directly from **Google Drive**. This bottleneck severely impacted training throughput by underutilizing GPU resources, as the data loading process could not keep pace with model execution.\n",
        "\n",
        "---\n",
        "\n",
        "## TFRecord-Based Data Pipeline Optimization\n",
        "\n",
        "To address this limitation, the dataset was converted into **TFRecord format**, a binary storage format optimized for TensorFlow workflows. This approach offers several key advantages:\n",
        "\n",
        "* **Efficient sequential reading** of data\n",
        "* **Reduced disk I/O overhead** through contiguous data storage\n",
        "* **Serialized data representation**, enabling faster parsing\n",
        "* **Asynchronous data loading and prefetching**, overlapping I/O with computation\n",
        "\n",
        "By enabling the data pipeline to operate concurrently with model training, this optimization significantly **maximized GPU utilization** and **reduced idle time during batch loading**, leading to a more efficient and stable training process.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz3GPaG0f5ea"
      },
      "source": [
        "# See TFRecord_Pipeline_HAM10000.ipynb for the implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JKtIVBBz3LIc"
      },
      "outputs": [],
      "source": [
        "TFRECORD_DIR = '/content/drive/MyDrive/HAM10000/processed_tfrecords/tfrecords'\n",
        "METADATA_DIR = '/content/drive/MyDrive/HAM10000/processed_tfrecords/metadata'\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/HAM10000/pre_trained_models'\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "IMG_SIZE = 224\n",
        "NUM_CLASSES = 7\n",
        "BATCH_SIZE = 32\n",
        "SEED = 42\n",
        "\n",
        "MODEL_CONFIGS = {\n",
        "    'ResNet152V2': {\n",
        "        'base_trainable': True,\n",
        "        'dense1_units': 1024,\n",
        "        'dense2_units': 512,\n",
        "        'use_alpha_dropout': False,\n",
        "        'learning_rate': 1e-4,\n",
        "        'epochs': 30,\n",
        "        'paper_accuracy': 89.95,\n",
        "        'paper_trainable_params': 60817543\n",
        "    },\n",
        "    'EfficientNetV2B0': {\n",
        "        'base_trainable': True,\n",
        "        'dense1_units': 1024,\n",
        "        'dense2_units': 256,\n",
        "        'use_alpha_dropout': False,\n",
        "        'learning_rate': 1e-3,\n",
        "        'epochs': 30,\n",
        "        'paper_accuracy': 86.74,\n",
        "        'paper_trainable_params': 7437207\n",
        "    },\n",
        "    'InceptionResNetV2': {\n",
        "        'base_trainable': True,\n",
        "        'dense1_units': 1024,\n",
        "        'dense2_units': 256,\n",
        "        'use_alpha_dropout': False,\n",
        "        'learning_rate': 1e-4,\n",
        "        'epochs': 30,\n",
        "        'paper_accuracy': 91.98,\n",
        "        'paper_trainable_params': 1840647\n",
        "    },\n",
        "    'MobileNetV3Large': {\n",
        "        'base_trainable': True,\n",
        "        'dense1_units': 1024,\n",
        "        'dense2_units': 512,\n",
        "        'use_alpha_dropout': True,\n",
        "        'learning_rate': 1e-3,\n",
        "        'epochs': 30,\n",
        "        'paper_accuracy': 88.78,\n",
        "        'paper_trainable_params': 1515527\n",
        "    }\n",
        "}\n",
        "\n",
        "IDX_TO_LABEL = {0: 'akiec', 1: 'bcc', 2: 'bkl', 3: 'df', 4: 'mel', 5: 'nv', 6: 'vasc'}\n",
        "\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-aV3b3a2823",
        "outputId": "b744b8f7-2423-4347-c40d-221cabe4c950"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train files: 36, Test files: 4\n"
          ]
        }
      ],
      "source": [
        "def get_tfrecord_files(tfrecord_dir, split):\n",
        "    pattern = os.path.join(tfrecord_dir, f'{split}-*.tfrecord')\n",
        "    return sorted(tf.io.gfile.glob(pattern))\n",
        "\n",
        "def parse_tfrecord(example_proto):\n",
        "    feature_desc = {\n",
        "        'image_id': tf.io.FixedLenFeature([], tf.string),\n",
        "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "        'image_bytes': tf.io.FixedLenFeature([], tf.string),\n",
        "        'dx': tf.io.FixedLenFeature([], tf.string),\n",
        "    }\n",
        "    return tf.io.parse_single_example(example_proto, feature_desc)\n",
        "\n",
        "train_files = get_tfrecord_files(TFRECORD_DIR, 'train')\n",
        "test_files = get_tfrecord_files(TFRECORD_DIR, 'test')\n",
        "print(f'Train files: {len(train_files)}, Test files: {len(test_files)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSACqTWgS7CS",
        "outputId": "152770e9-6c16-407c-ba96-462c2b4287a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Counting samples...\n",
            "Train: 9013, Test: 1002\n",
            "Class weights:\n",
            "  akiec: 4.379\n",
            "  bcc: 2.781\n",
            "  bkl: 1.302\n",
            "  df: 12.501\n",
            "  mel: 1.285\n",
            "  nv: 0.213\n",
            "  vasc: 10.059\n"
          ]
        }
      ],
      "source": [
        "def count_distribution(files):\n",
        "    dataset = tf.data.TFRecordDataset(files).map(parse_tfrecord)\n",
        "    counts = Counter()\n",
        "    for ex in dataset:\n",
        "        counts[ex['label'].numpy()] += 1\n",
        "    return dict(counts)\n",
        "\n",
        "print('Counting samples...')\n",
        "train_dist = count_distribution(train_files)\n",
        "TRAIN_SAMPLES = sum(train_dist.values())\n",
        "TEST_SAMPLES = sum(count_distribution(test_files).values())\n",
        "print(f'Train: {TRAIN_SAMPLES}, Test: {TEST_SAMPLES}')\n",
        "\n",
        "CLASS_WEIGHTS = {k: TRAIN_SAMPLES / (NUM_CLASSES * v) for k, v in train_dist.items()}\n",
        "print('Class weights:')\n",
        "for idx in sorted(CLASS_WEIGHTS.keys()):\n",
        "    print(f'  {IDX_TO_LABEL[idx]}: {CLASS_WEIGHTS[idx]:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "m3eLYwjQTGH8"
      },
      "outputs": [],
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "    tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "    tf.keras.layers.RandomRotation(factor=90/360, fill_mode=\"reflect\"),\n",
        "    tf.keras.layers.RandomZoom(height_factor=(-0.1, 0.1),\n",
        "                               width_factor=(-0.1, 0.1),\n",
        "                               fill_mode=\"reflect\"),\n",
        "], name=\"paper_augmentation\")\n",
        "\n",
        "def augment(image, label):\n",
        "    # image este în [0,1] la tine => perfect pentru layers\n",
        "    image = data_augmentation(image, training=True)\n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx0Gug4xdUUt",
        "outputId": "823826fb-400d-4b5b-b7b2-d6d17d77a506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Preprocessing functions defined\n"
          ]
        }
      ],
      "source": [
        "def get_preprocess_fn(model_name):\n",
        "    if model_name == 'ResNet152V2':\n",
        "        return tf.keras.applications.resnet_v2.preprocess_input\n",
        "    elif model_name == 'EfficientNetV2B0':\n",
        "        return lambda x: (x / 127.5) - 1.0\n",
        "    elif model_name == 'InceptionResNetV2':\n",
        "        return tf.keras.applications.inception_resnet_v2.preprocess_input\n",
        "    elif model_name == 'MobileNetV3Large':\n",
        "        return lambda x: (x / 127.5) - 1.0\n",
        "    return lambda x: x\n",
        "\n",
        "print('Preprocessing functions defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rc5x2GO4dvpc",
        "outputId": "61d93f87-1692-428c-822f-8a702a52b30e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset functions defined\n"
          ]
        }
      ],
      "source": [
        "def create_train_ds(files, batch_size, preprocess_fn):\n",
        "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    ds = ds.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    def decode(ex):\n",
        "        img = tf.io.decode_jpeg(ex['image_bytes'], channels=3)\n",
        "        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "        img = tf.cast(img, tf.float32) / 255.0\n",
        "        return img, ex['label']\n",
        "\n",
        "    ds = ds.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.repeat()\n",
        "    ds = ds.shuffle(2000,seed = SEED, reshuffle_each_iteration=True)\n",
        "    ds = ds.map(augment, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    def apply_preprocess(img, label):\n",
        "        return preprocess_fn(img * 255.0), label\n",
        "\n",
        "    ds = ds.map(apply_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size, drop_remainder=True)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "def create_test_ds(files, batch_size, preprocess_fn):\n",
        "    ds = tf.data.TFRecordDataset(files, num_parallel_reads=tf.data.AUTOTUNE)\n",
        "    ds = ds.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "    def decode(ex):\n",
        "        img = tf.io.decode_jpeg(ex['image_bytes'], channels=3)\n",
        "        img = tf.image.resize(img, [IMG_SIZE, IMG_SIZE])\n",
        "        img = tf.cast(img, tf.float32) / 255.0\n",
        "        return img, ex['label']\n",
        "\n",
        "    ds = ds.map(decode, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.cache()\n",
        "\n",
        "    def apply_preprocess(img, label):\n",
        "        return preprocess_fn(img * 255.0), label\n",
        "\n",
        "    ds = ds.map(apply_preprocess, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch_size, drop_remainder=False)\n",
        "    ds = ds.prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "print('Dataset functions defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arZf0eXzhevs",
        "outputId": "77b3d2e3-ff99-4756-99c0-bd543e3a4981"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model builder defined\n"
          ]
        }
      ],
      "source": [
        "def build_model(model_name, config):\n",
        "\n",
        "    input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
        "    # Get base model\n",
        "    if model_name == 'ResNet152V2':\n",
        "        base = tf.keras.applications.ResNet152V2( include_top=False, weights='imagenet', input_shape=input_shape )\n",
        "    elif model_name == 'EfficientNetV2B0':\n",
        "        base = tf.keras.applications.EfficientNetV2B0( include_top=False, weights='imagenet', input_shape=input_shape )\n",
        "    elif model_name == 'InceptionResNetV2':\n",
        "        base = tf.keras.applications.InceptionResNetV2( include_top=False, weights='imagenet', input_shape=input_shape )\n",
        "    elif model_name == 'MobileNetV3Large':\n",
        "        base = tf.keras.applications.MobileNetV3Large( include_top=False, weights='imagenet', input_shape=input_shape )\n",
        "\n",
        "    base.trainable = config['base_trainable']\n",
        "\n",
        "    # Build classification head - EXACT from paper\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "\n",
        "    # For frozen models, use training=False\n",
        "    if config['base_trainable']:\n",
        "        x = base(inputs, training=True)\n",
        "    else:\n",
        "        x = base(inputs, training=False)\n",
        "\n",
        "    # Global Average Pooling\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "\n",
        "    # Dense 1\n",
        "    if config['use_alpha_dropout']:\n",
        "        x = tf.keras.layers.Dense(config['dense1_units'], activation='selu')(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.AlphaDropout(0.1)(x)\n",
        "    else:\n",
        "        x = tf.keras.layers.Dense(config['dense1_units'], activation='relu')(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Dense 2\n",
        "    if config['use_alpha_dropout']:\n",
        "        x = tf.keras.layers.Dense(config['dense2_units'], activation='selu')(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.AlphaDropout(0.1)(x)\n",
        "    else:\n",
        "        x = tf.keras.layers.Dense(config['dense2_units'], activation='relu')(x)\n",
        "        x = tf.keras.layers.BatchNormalization()(x)\n",
        "        x = tf.keras.layers.Dropout(0.3)(x)\n",
        "\n",
        "    # Output\n",
        "    outputs = tf.keras.layers.Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs, name=model_name)\n",
        "\n",
        "    # Print summary\n",
        "    total_params = model.count_params()\n",
        "    trainable_params = sum(tf.keras.backend.count_params(w) for w in model.trainable_weights)\n",
        "\n",
        "    status = 'UNFROZEN' if config['base_trainable'] else 'FROZEN'\n",
        "    print(f'\\n{model_name} ({status}):')\n",
        "    print(f'  Architecture: GAP -> Dense({config[\"dense1_units\"]}) -> Dense({config[\"dense2_units\"]}) -> Dense(7)')\n",
        "    print(f'  Total params: {total_params:,}')\n",
        "    print(f'  Trainable params: {trainable_params:,}')\n",
        "    print(f'  Paper trainable: {config[\"paper_trainable_params\"]:,}')\n",
        "    print(f'  Match: {\"YES\" if abs(trainable_params - config[\"paper_trainable_params\"]) < 100000 else \"NO\"}')\n",
        "\n",
        "    return model\n",
        "\n",
        "print('Model builder defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mVcHr8aupY0r",
        "outputId": "64b18f41-91e2-4726-8cf1-e16893d9c6ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Callbacks defined\n"
          ]
        }
      ],
      "source": [
        "def get_callbacks(model_name):\n",
        "    return [\n",
        "        tf.keras.callbacks.ModelCheckpoint(\n",
        "            os.path.join(OUTPUT_DIR, f'{model_name}_best.keras'),\n",
        "            monitor='val_accuracy', mode='max', save_best_only=True, verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor='val_accuracy', mode='max', patience=10,\n",
        "            restore_best_weights=True, verbose=1\n",
        "        ),\n",
        "        tf.keras.callbacks.ReduceLROnPlateau(\n",
        "            monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1\n",
        "        )\n",
        "    ]\n",
        "\n",
        "print('Callbacks defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an-9y7mYpb6u",
        "outputId": "448198a6-a8b8-42d1-8593-b94c0fd3f66b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Evaluation functions defined\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, test_ds, model_name):\n",
        "    print(f'Evaluating {model_name}...')\n",
        "\n",
        "    y_true, y_pred, y_proba = [], [], []\n",
        "    for imgs, labels in test_ds:\n",
        "        preds = model.predict(imgs, verbose=0)\n",
        "        y_proba.extend(preds)\n",
        "        y_pred.extend(np.argmax(preds, axis=1))\n",
        "        y_true.extend(labels.numpy())\n",
        "\n",
        "    y_true, y_pred, y_proba = np.array(y_true), np.array(y_pred), np.array(y_proba)\n",
        "\n",
        "    acc = np.mean(y_true == y_pred)\n",
        "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
        "    try:\n",
        "        auc = roc_auc_score(y_true, y_proba, multi_class='ovr', average='weighted')\n",
        "    except:\n",
        "        auc = 0.0\n",
        "\n",
        "    print(f'Accuracy: {acc*100:.2f}%')\n",
        "    print(f'Precision: {prec:.4f}, Recall: {rec:.4f}, F1: {f1:.4f}, AUC: {auc:.4f}')\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'auc': auc,\n",
        "        'cm': confusion_matrix(y_true, y_pred)\n",
        "    }\n",
        "\n",
        "def plot_results(history, cm, model_name, config):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "    # Accuracy\n",
        "    axes[0].plot(history.history['accuracy'], label='Train')\n",
        "    axes[0].plot(history.history['val_accuracy'], label='Val')\n",
        "    axes[0].axhline(y=config['paper_accuracy']/100, color='r', linestyle='--', label=f'Paper ({config[\"paper_accuracy\"]}%)')\n",
        "    axes[0].set_title(f'{model_name} - Accuracy')\n",
        "    axes[0].legend()\n",
        "    axes[0].grid(True)\n",
        "\n",
        "    # Loss\n",
        "    axes[1].plot(history.history['loss'], label='Train')\n",
        "    axes[1].plot(history.history['val_loss'], label='Val')\n",
        "    axes[1].set_title(f'{model_name} - Loss')\n",
        "    axes[1].legend()\n",
        "    axes[1].grid(True)\n",
        "\n",
        "    # Confusion Matrix\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[2],\n",
        "                xticklabels=[IDX_TO_LABEL[i] for i in range(NUM_CLASSES)],\n",
        "                yticklabels=[IDX_TO_LABEL[i] for i in range(NUM_CLASSES)])\n",
        "    axes[2].set_title(f'{model_name} - Confusion Matrix')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(OUTPUT_DIR, f'{model_name}_results.png'), dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "print('Evaluation functions defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHNj_236pgvH",
        "outputId": "f3fdf8e4-9eb9-48a1-fcfe-0698207fcce7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training function defined\n"
          ]
        }
      ],
      "source": [
        "def train_model(model_name):\n",
        "    config = MODEL_CONFIGS[model_name]\n",
        "\n",
        "    print(f'\\n{\"#\"*70}')\n",
        "    print(f'# TRAINING: {model_name}')\n",
        "    print(f'# Base: {\"UNFROZEN\" if config[\"base_trainable\"] else \"FROZEN\"}')\n",
        "    print(f'# Architecture: Dense({config[\"dense1_units\"]}) -> Dense({config[\"dense2_units\"]})')\n",
        "    print(f'# Learning Rate: {config[\"learning_rate\"]}')\n",
        "    print(f'# Paper Accuracy: {config[\"paper_accuracy\"]}%')\n",
        "    print(f'{\"#\"*70}')\n",
        "\n",
        "    start = time.time()\n",
        "\n",
        "    # Create datasets\n",
        "    preprocess_fn = get_preprocess_fn(model_name)\n",
        "    train_ds = create_train_ds(train_files, BATCH_SIZE, preprocess_fn)\n",
        "    test_ds = create_test_ds(test_files, BATCH_SIZE, preprocess_fn)\n",
        "\n",
        "    steps = TRAIN_SAMPLES // BATCH_SIZE\n",
        "    print(f'Steps per epoch: {steps}')\n",
        "\n",
        "    # Build model\n",
        "    model = build_model(model_name, config)\n",
        "\n",
        "    # Compile\n",
        "    print(f'\\nCompiling with LR={config[\"learning_rate\"]}')\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=config['learning_rate']),\n",
        "        loss='sparse_categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        train_ds,\n",
        "        epochs=config['epochs'],\n",
        "        steps_per_epoch=steps,\n",
        "        validation_data=test_ds,\n",
        "        class_weight=CLASS_WEIGHTS,\n",
        "        callbacks=get_callbacks(model_name),\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate\n",
        "    results = evaluate_model(model, test_ds, model_name)\n",
        "\n",
        "    # Plot\n",
        "    plot_results(history, results['cm'], model_name, config)\n",
        "\n",
        "    # Save\n",
        "    model.save(os.path.join(OUTPUT_DIR, f'{model_name}_final.keras'))\n",
        "\n",
        "    elapsed = (time.time() - start) / 60\n",
        "    print(f'\\nTime: {elapsed:.1f} min')\n",
        "    print(f'Our accuracy: {results[\"accuracy\"]*100:.2f}% vs Paper: {config[\"paper_accuracy\"]}%')\n",
        "\n",
        "    results['time'] = elapsed\n",
        "    results['history'] = history.history\n",
        "    results['paper_accuracy'] = config['paper_accuracy']\n",
        "\n",
        "    tf.keras.backend.clear_session()\n",
        "    return results\n",
        "\n",
        "print('Training function defined')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg0JbdZxZcQl",
        "outputId": "026a8059-93f9-4db7-a827-4e0e328440d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet152V2         : range = [-1.00, 0.96]\n",
            "EfficientNetV2B0    : range = [-1.00, 0.96]\n",
            "InceptionResNetV2   : range = [-1.00, 0.96]\n",
            "MobileNetV3Large    : range = [-1.00, 0.96]\n"
          ]
        }
      ],
      "source": [
        "# Test each model's preprocessing\n",
        "for model_name in ['ResNet152V2', 'EfficientNetV2B0', 'InceptionResNetV2', 'MobileNetV3Large']:\n",
        "    preprocess_fn = get_preprocess_fn(model_name)\n",
        "    test_ds = create_test_ds(test_files, 4, preprocess_fn)\n",
        "\n",
        "    for images, labels in test_ds.take(1):\n",
        "        min_val = tf.reduce_min(images).numpy()\n",
        "        max_val = tf.reduce_max(images).numpy()\n",
        "        print(f\"{model_name:20s}: range = [{min_val:.2f}, {max_val:.2f}]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JqgdRqiJpku_",
        "outputId": "9d4fdebd-4711-49b2-ce40-1b50c14d19b6"
      },
      "outputs": [],
      "source": [
        "resnet_results = train_model('ResNet152V2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GlXq6mv7pmoH",
        "outputId": "f012c570-efb8-4150-eec0-73c43dbb444f"
      },
      "outputs": [],
      "source": [
        "efficient_results = train_model('EfficientNetV2B0')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--Cdze0Xpq7R"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "inception_results = train_model('InceptionResNetV2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8vfg9pdpuSQ"
      },
      "outputs": [],
      "source": [
        "tf.keras.backend.clear_session()\n",
        "mobile_results = train_model('MobileNetV3Large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SEW-sVyVBApd"
      },
      "outputs": [],
      "source": [
        "# ============================================\n",
        "# DEBUG CELL - Rulează asta pentru diagnostic\n",
        "# ============================================\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"DIAGNOSTIC COMPLET\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# 1. Verifică funcția curentă\n",
        "import inspect\n",
        "print(\"\\n1. FUNCȚIA CREATE_TRAIN_DS (primele 20 linii):\")\n",
        "source = inspect.getsource(create_train_ds)\n",
        "for i, line in enumerate(source.split('\\n')[:20]):\n",
        "    print(f\"  {i+1}: {line}\")\n",
        "\n",
        "# 2. Verifică dacă .repeat() e în funcție\n",
        "print(f\"\\n2. '.repeat()' în funcție: {'DA ✅' if '.repeat()' in source else 'NU ❌'}\")\n",
        "\n",
        "# 3. Test practic - verifică dacă dataset-ul se repetă\n",
        "print(\"\\n3. TEST PRACTIC - Câte batch-uri pot lua?\")\n",
        "test_preprocess = get_preprocess_fn('ResNet152V2')\n",
        "test_ds = create_train_ds(train_files, BATCH_SIZE, test_preprocess)\n",
        "\n",
        "batch_count = 0\n",
        "for batch in test_ds.take(400):  # 400 batches × 32 = 12,800 > 9,013 samples\n",
        "    batch_count += 1\n",
        "    if batch_count % 100 == 0:\n",
        "        print(f\"  ... {batch_count} batches\")\n",
        "\n",
        "print(f\"\\n  Total batches obținute: {batch_count}\")\n",
        "expected_without_repeat = TRAIN_SAMPLES // BATCH_SIZE  # ~281\n",
        "print(f\"  Fără .repeat() ar fi: ~{expected_without_repeat}\")\n",
        "print(f\"  Cu .repeat() ar fi: 400\")\n",
        "\n",
        "if batch_count >= 400:\n",
        "    print(\"  ✅ Dataset-ul SE REPETĂ corect!\")\n",
        "else:\n",
        "    print(\"  ❌ Dataset-ul NU se repetă! Problema e aici!\")\n",
        "\n",
        "# 4. Verifică dimensiunile unui batch\n",
        "print(\"\\n4. VERIFICARE BATCH:\")\n",
        "for images, labels in test_ds.take(1):\n",
        "    print(f\"  Image shape: {images.shape}\")\n",
        "    print(f\"  Labels shape: {labels.shape}\")\n",
        "    print(f\"  Image range: [{tf.reduce_min(images).numpy():.3f}, {tf.reduce_max(images).numpy():.3f}]\")\n",
        "    print(f\"  Unique labels in batch: {np.unique(labels.numpy())}\")\n",
        "\n",
        "# 5. Verifică class weights\n",
        "print(\"\\n5. CLASS WEIGHTS:\")\n",
        "for idx in sorted(CLASS_WEIGHTS.keys()):\n",
        "    print(f\"  {IDX_TO_LABEL[idx]}: {CLASS_WEIGHTS[idx]:.3f}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"DIAGNOSTIC COMPLET\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Os-elKMs87rC"
      },
      "outputs": [],
      "source": [
        "train_ds = create_train_ds(train_files, BATCH_SIZE, preprocess_fn)\n",
        "print(\"Cardinality:\", train_ds.cardinality().numpy())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
