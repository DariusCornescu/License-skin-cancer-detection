{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DK-3D24VEfkH"
   },
   "source": [
    "# HAM10000 Complete TFRecord Pipeline - Google Drive Edition\n",
    "Pipeline complet pentru dataset-ul HAM10000 :\n",
    "- Split stratificat deterministic (90% train, 10% test)\n",
    "- Generare TFRecords shard-uite\n",
    "- tf.data pipeline cu augmentare\n",
    "- Preprocessing pentru ResNet152V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aN3HM0xEEfkI"
   },
   "source": [
    "## 1. Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 63806,
     "status": "ok",
     "timestamp": 1768439820567,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "pydCKDPPEfkI"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"✓ Google Drive mounted successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oEDRkPGlEfkJ"
   },
   "source": [
    "## 2. Setup și Import-uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9616,
     "status": "ok",
     "timestamp": 1768439831912,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "P88OqkKgEfkJ"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"GPU available: {tf.config.list_physical_devices('GPU')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XBD_uuOOEfkJ"
   },
   "source": [
    "## 3. Configurare Paths și Constante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1768439831927,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "YOKDB_VkEfkJ"
   },
   "outputs": [],
   "source": [
    "DRIVE_ROOT = '/content/drive/MyDrive/HAM10000'\n",
    "METADATA_PATH = os.path.join(DRIVE_ROOT, 'HAM10000_metadata.csv')\n",
    "IMAGE_ROOTS = [ os.path.join(DRIVE_ROOT, 'HAM10000_images_part_1'), os.path.join(DRIVE_ROOT, 'HAM10000_images_part_2') ]\n",
    "\n",
    "OUTPUT_DIR = '/content/ham10000_processed'\n",
    "TFRECORD_DIR = os.path.join(OUTPUT_DIR, 'tfrecords')\n",
    "METADATA_OUTPUT_DIR = os.path.join(OUTPUT_DIR, 'metadata')\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(TFRECORD_DIR, exist_ok=True)\n",
    "os.makedirs(METADATA_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# Constante\n",
    "IMG_SIZE = 224\n",
    "EXAMPLES_PER_SHARD = 256\n",
    "TRAIN_SPLIT = 0.90\n",
    "TEST_SPLIT = 0.10\n",
    "\n",
    "print(\"Checking paths...\")\n",
    "print(f\"  Metadata exists: {os.path.exists(METADATA_PATH)}\")\n",
    "print(f\"  Images part 1 exists: {os.path.exists(IMAGE_ROOTS[0])}\")\n",
    "print(f\"  Images part 2 exists: {os.path.exists(IMAGE_ROOTS[1])}\")\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(f\"TFRecord directory: {TFRECORD_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mnBffbOEfkK"
   },
   "source": [
    "## 4. Citire Metadata și Construire Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 490
    },
    "executionInfo": {
     "elapsed": 33959,
     "status": "ok",
     "timestamp": 1768439865889,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "xUbBcImZEfkK"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(METADATA_PATH)\n",
    "print(f\"Total samples in metadata: {len(df)}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\nClass distribution:\\n{df['dx'].value_counts()}\")\n",
    "\n",
    "def find_image_path(image_id, roots):\n",
    "    \"\"\"Caută imaginea în toate directoarele rădăcină\"\"\"\n",
    "\n",
    "    for root in roots:\n",
    "        path = os.path.join(root, f\"{image_id}.jpg\")\n",
    "        if os.path.exists(path):\n",
    "            return path\n",
    "    return None\n",
    "\n",
    "print(\"\\nBuilding image paths...\")\n",
    "df['image_path'] = df['image_id'].apply(lambda x: find_image_path(x, IMAGE_ROOTS))\n",
    "\n",
    "missing = df['image_path'].isna().sum()\n",
    "if missing > 0:\n",
    "    print(f\"WARNING: {missing} images not found!\")\n",
    "    df = df[df['image_path'].notna()].reset_index(drop=True)\n",
    "    print(f\"Continuing with {len(df)} images\")\n",
    "else:\n",
    "    print(f\"✓ All {len(df)} images found successfully\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3h6-d0n0EfkK"
   },
   "source": [
    "## 5. Creare Label Map (Stabil și Salvat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1768439865928,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "JY5nOTiwEfkK"
   },
   "outputs": [],
   "source": [
    "unique_labels = sorted(df['dx'].unique())\n",
    "label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "inverse_label_map = {idx: label for label, idx in label_map.items()}\n",
    "\n",
    "print(\"Label mapping:\")\n",
    "for label, idx in label_map.items():\n",
    "    count = (df['dx'] == label).sum()\n",
    "    print(f\"  {idx}: {label} ({count} samples)\")\n",
    "\n",
    "label_map_path = os.path.join(METADATA_OUTPUT_DIR, 'label_map.json')\n",
    "with open(label_map_path, 'w') as f:\n",
    "    json.dump({\n",
    "        'label_to_idx': label_map,\n",
    "        'idx_to_label': inverse_label_map\n",
    "    }, f, indent=2)\n",
    "print(f\"\\n✓ Label map saved to: {label_map_path}\")\n",
    "\n",
    "df['label'] = df['dx'].map(label_map)\n",
    "NUM_CLASSES = len(label_map)\n",
    "print(f\"\\nTotal classes: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gh35Y-CwEfkL"
   },
   "source": [
    "## 6. Split Stratificat (Train/Test) cu Seed Fix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35,
     "status": "ok",
     "timestamp": 1768439865965,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "jF9GYA5iEfkL"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split( df, test_size=TEST_SPLIT, stratify=df['label'], random_state=SEED )\n",
    "\n",
    "train_df = train_df.copy()\n",
    "test_df = test_df.copy()\n",
    "train_df['split'] = 'train'\n",
    "test_df['split'] = 'test'\n",
    "splits_df = pd.concat([train_df, test_df], ignore_index=True)\n",
    "\n",
    "print(\"Split distribution:\")\n",
    "print(f\"  Train: {len(train_df)} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"  Test:  {len(test_df)} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\nClass distribution per split:\")\n",
    "for split in ['train', 'test']:\n",
    "    split_df = splits_df[splits_df['split'] == split]\n",
    "    print(f\"\\n{split.upper()}:\")\n",
    "    dist = split_df['dx'].value_counts()\n",
    "    for label, count in dist.items():\n",
    "        pct = count / len(split_df) * 100\n",
    "        print(f\"  {label}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "splits_path = os.path.join(METADATA_OUTPUT_DIR, 'splits.csv')\n",
    "splits_df[['image_id', 'image_path', 'dx', 'label', 'split']].to_csv(splits_path, index=False)\n",
    "print(f\"\\n✓ Splits saved to: {splits_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BHFtz7exEfkL"
   },
   "source": [
    "## 7. Funcții Helper pentru TFRecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1768439865982,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "F55T1fWxEfkL"
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    if isinstance(value, str):\n",
    "        value = value.encode('utf-8')\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_tf_example(image_id, image_path, label, dx):\n",
    "    \"\"\"\n",
    "    Creează un tf.train.Example pentru un eșantion.\n",
    "\n",
    "    Args:\n",
    "        image_id: ID-ul imaginii (string)\n",
    "        image_path: Path către imaginea JPEG\n",
    "        label: Label numeric (int)\n",
    "        dx: Label text (string)\n",
    "\n",
    "    Returns:\n",
    "        tf.train.Example serializat\n",
    "    \"\"\"\n",
    "    with open(image_path, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "\n",
    "    feature = { 'image_id': _bytes_feature(image_id), 'label': _int64_feature(label), 'image_bytes': _bytes_feature(image_bytes), 'dx': _bytes_feature(dx) }\n",
    "\n",
    "    example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "    return example.SerializeToString()\n",
    "\n",
    "print(\"✓ TFRecord helper functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JPEo3SKhEfkL"
   },
   "source": [
    "## 8. Generare TFRecords Shard-uite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 537
    },
    "executionInfo": {
     "elapsed": 1104729,
     "status": "error",
     "timestamp": 1768440970714,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "XzMZB_QLEfkM"
   },
   "outputs": [],
   "source": [
    "def write_tfrecords(df, split_name, output_dir, examples_per_shard=256):\n",
    "    \"\"\"\n",
    "    Scrie TFRecords shard-uite pentru un split.\n",
    "\n",
    "    Args:\n",
    "        df: DataFrame cu datele\n",
    "        split_name: 'train' sau 'test'\n",
    "        output_dir: Director pentru TFRecords\n",
    "        examples_per_shard: Număr de exemple per shard\n",
    "\n",
    "    Returns:\n",
    "        Lista de paths către TFRecords create\n",
    "    \"\"\"\n",
    "    num_examples = len(df)\n",
    "    num_shards = (num_examples + examples_per_shard - 1) // examples_per_shard\n",
    "\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Writing {split_name.upper()} TFRecords\")\n",
    "    print(f\"  Total examples: {num_examples}\")\n",
    "    print(f\"  Examples per shard: {examples_per_shard}\")\n",
    "    print(f\"  Number of shards: {num_shards}\")\n",
    "    print(f\"{'='*60}\")\n",
    "\n",
    "    tfrecord_paths = []\n",
    "\n",
    "    for shard_idx in tqdm(range(num_shards), desc=f\"Writing {split_name} shards\"):\n",
    "        # Compute the range for this shard\n",
    "        start_idx = shard_idx * examples_per_shard\n",
    "        end_idx = min(start_idx + examples_per_shard, num_examples)\n",
    "\n",
    "        # Name for shard_file\n",
    "        shard_filename = f\"{split_name}-{shard_idx:04d}-of-{num_shards:04d}.tfrecord\"\n",
    "        shard_path = os.path.join(output_dir, shard_filename)\n",
    "        tfrecord_paths.append(shard_path)\n",
    "\n",
    "        # Write shard\n",
    "        with tf.io.TFRecordWriter(shard_path) as writer:\n",
    "            for idx in range(start_idx, end_idx):\n",
    "                row = df.iloc[idx]\n",
    "                tf_example = create_tf_example( image_id=row['image_id'], image_path=row['image_path'], label=row['label'], dx=row['dx'] )\n",
    "                writer.write(tf_example)\n",
    "\n",
    "    print(f\"✓ Wrote {num_shards} shards with {num_examples} total examples\")\n",
    "    return tfrecord_paths\n",
    "\n",
    "# Write TFRecords for each split\n",
    "tfrecord_info = {}\n",
    "\n",
    "for split_name in ['train', 'test']:\n",
    "    split_df = splits_df[splits_df['split'] == split_name].reset_index(drop=True)\n",
    "    paths = write_tfrecords(\n",
    "        df=split_df,\n",
    "        split_name=split_name,\n",
    "        output_dir=TFRECORD_DIR,\n",
    "        examples_per_shard=EXAMPLES_PER_SHARD\n",
    "    )\n",
    "    tfrecord_info[split_name] = {\n",
    "        'num_examples': len(split_df),\n",
    "        'num_shards': len(paths),\n",
    "        'paths': paths\n",
    "    }\n",
    "\n",
    "# Save TFRecords informations\n",
    "tfrecord_info_path = os.path.join(METADATA_OUTPUT_DIR, 'tfrecord_info.json')\n",
    "with open(tfrecord_info_path, 'w') as f:\n",
    "    # Convert paths to relative pentru portabilitate\n",
    "    info_to_save = {}\n",
    "    for split, data in tfrecord_info.items():\n",
    "        info_to_save[split] = {\n",
    "            'num_examples': data['num_examples'],\n",
    "            'num_shards': data['num_shards'],\n",
    "            'paths': [os.path.basename(p) for p in data['paths']]\n",
    "        }\n",
    "    json.dump(info_to_save, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ TFRecord info saved to: {tfrecord_info_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1214100,
     "status": "aborted",
     "timestamp": 1768440970702,
     "user": {
      "displayName": "Cornescu Darius",
      "userId": "14196931393174301559"
     },
     "user_tz": -120
    },
    "id": "7fqBmil3J_2D"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
